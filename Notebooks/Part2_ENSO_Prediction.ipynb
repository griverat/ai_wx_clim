{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: ENSO Phase Prediction\n",
                "\n",
                "**Goal**: Predict the ENSO phase (Neutral / El Niño / La Niña) 1–3 months ahead using the ONI computed from ERSSTv6 data.\n",
                "\n",
                "## 1. What is ENSO?\n",
                "\n",
                "![enso](imgs/enso.png)\n",
                "\n",
                "The **El Niño–Southern Oscillation (ENSO)** is a climate phenomenon in the Pacific Ocean characterized by periodic warming and cooling of sea surface temperatures.\n",
                "\n",
                "- **El Niño**: Warmer-than-average SSTs in the central/eastern equatorial Pacific -> droughts in Australia/SE Asia, flooding in South America, warmer winters in North America.\n",
                "- **La Niña**: Cooler-than-average SSTs in the same region -> opposite effects.\n",
                "- **Neutral**: Near-average conditions.\n",
                "\n",
                "ENSO is one of the most important drivers of global climate variability. Predicting it months in advance is a major challenge.\n",
                "\n",
                "### The Oceanic Niño Index (ONI)\n",
                "The **ONI** is the standard metric for ENSO monitoring. It is computed as:\n",
                "1. Average SST anomalies over the **Niño 3.4 region** (5°S–5°N, 170°W–120°W)\n",
                "2. Apply a **3-month centered running mean** to smooth out noise\n",
                "\n",
                "ENSO phase is then defined by thresholds on ONI:\n",
                "- **El Niño**: ONI ≥ +0.5°C\n",
                "- **La Niña**: ONI ≤ −0.5°C\n",
                "- **Neutral**: −0.5°C < ONI < +0.5°C\n",
                "\n",
                "### Our Task\n",
                "Given the **last 12 months of ONI values**, predict the **ENSO class** for each of the **next 3 months**. This is a **sequence -> classification** problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import xarray as xr\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import EarlyStopping\n",
                "\n",
                "device = torch.device(\n",
                "    \"cuda\" if torch.cuda.is_available()\n",
                "    else \"mps\" if torch.backends.mps.is_available()\n",
                "    else \"cpu\"\n",
                ")\n",
                "print(f\"Using device: {device}\")\n",
                "\n",
                "plt.rcParams[\"font.family\"] = \"monospace\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load ERSSTv6 Data\n",
                "\n",
                "We load the combined dataset that was prepared in Part 2A."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds = xr.open_dataset(\"../data/processed/ersstv6_combined.nc\")\n",
                "print(f\"Time: {str(ds.time.values[0])[:7]} to {str(ds.time.values[-1])[:7]} ({len(ds.time)} months)\")\n",
                "print(f\"Grid: {len(ds.lat)} lat × {len(ds.lon)} lon\")\n",
                "print(f\"Variables: {list(ds.data_vars)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compute the Oceanic Niño Index (ONI)\n",
                "\n",
                "The ONI is computed in two steps:\n",
                "1. **Spatial average**: Area-weighted mean SSTA over the Niño 3.4 box (5°S–5°N, 170°W–120°W)\n",
                "2. **Temporal smoothing**: 3-month centered running mean"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Niño 3.4 region: 5°S-5°N, 170°W-120°W\n",
                "# In 0-360° longitude: 170°W = 190°, 120°W = 240°\n",
                "nino34 = ds.ssta.sel(lat=slice(-5, 5), lon=slice(190, 240))\n",
                "\n",
                "# Area-weighted spatial average\n",
                "weights = np.cos(np.deg2rad(nino34.lat))\n",
                "nino34_index = nino34.weighted(weights).mean(dim=['lat', 'lon'])\n",
                "\n",
                "# 3-month centered running mean → ONI\n",
                "oni = nino34_index.rolling(time=3, center=True).mean().dropna('time')\n",
                "\n",
                "oni_series = oni.to_series()\n",
                "oni_series.name = 'ONI'\n",
                "\n",
                "print(f\"ONI time series: {len(oni_series)} months\")\n",
                "print(f\"Range: {oni_series.index[0].strftime('%Y-%m')} to {oni_series.index[-1].strftime('%Y-%m')}\")\n",
                "print(f\"Mean: {oni_series.mean():.3f}, Std: {oni_series.std():.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(15, 4))\n",
                "\n",
                "ax.fill_between(oni_series.index, oni_series.values, 0.5,\n",
                "                where=oni_series.values >= 0.5, color='red', alpha=0.4, label='El Niño')\n",
                "ax.fill_between(oni_series.index, oni_series.values, -0.5,\n",
                "                where=oni_series.values <= -0.5, color='blue', alpha=0.4, label='La Niña')\n",
                "ax.plot(oni_series.index, oni_series.values, color='black', linewidth=0.8)\n",
                "ax.axhline(0.5, color='red', linestyle='--', alpha=0.5)\n",
                "ax.axhline(-0.5, color='blue', linestyle='--', alpha=0.5)\n",
                "ax.axhline(0, color='gray', linewidth=0.5)\n",
                "\n",
                "ax.set_title('Oceanic Niño Index (ONI) — Computed from ERSSTv6')\n",
                "ax.set_ylabel('ONI (°C)')\n",
                "ax.set_xlabel('Year')\n",
                "ax.legend(loc='upper left')\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Label Each Month by ENSO Phase\n",
                "\n",
                "Using the standard ONI thresholds:\n",
                "- **0 = Neutral**: −0.5 < ONI < 0.5\n",
                "- **1 = El Niño**: ONI ≥ 0.5\n",
                "- **2 = La Niña**: ONI ≤ −0.5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Label each month\n",
                "def oni_to_label(val):\n",
                "    if val >= 0.5:\n",
                "        return 1  # El Niño\n",
                "    elif val <= -0.5:\n",
                "        return 2  # La Niña\n",
                "    else:\n",
                "        return 0  # Neutral\n",
                "\n",
                "labels = oni_series.apply(oni_to_label).values\n",
                "\n",
                "phase_names = ['Neutral', 'El Niño', 'La Niña']\n",
                "for i, name in enumerate(phase_names):\n",
                "    count = (labels == i).sum()\n",
                "    print(f\"  {name}: {count} months ({100*count/len(labels):.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Prepare Sequences & DataLoaders\n",
                "\n",
                "We create a sliding window dataset:\n",
                "- **Input**: 12 consecutive months of ONI values\n",
                "- **Target**: ENSO class at lead 1, 2, and 3 months ahead\n",
                "\n",
                "First, we define the class that will hanlde our dataset for ingestion to the ML model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ONIDataset(Dataset):\n",
                "    def __init__(self, oni_values, labels, seq_len=12, n_leads=3):\n",
                "        self.seq_len = seq_len\n",
                "        self.n_leads = n_leads\n",
                "        self.samples = []\n",
                "        self.targets = []\n",
                "        \n",
                "        for i in range(len(oni_values) - seq_len - n_leads):\n",
                "            x = oni_values[i : i + seq_len]\n",
                "            y = [labels[i + seq_len + lead] for lead in range(n_leads)]\n",
                "            self.samples.append(x)\n",
                "            self.targets.append(y)\n",
                "        \n",
                "        self.samples = torch.tensor(np.array(self.samples), dtype=torch.float32)\n",
                "        self.targets = torch.tensor(np.array(self.targets), dtype=torch.long)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return self.samples[idx], self.targets[idx]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can now do the split of our dataset. It is a good practise to have 3 sets: training, validation and testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEQ_LEN = 12  # 12 months of ONI history\n",
                "N_LEADS = 3   # predict 1, 2, 3 months ahead\n",
                "\n",
                "# 70/15/15 split\n",
                "\n",
                "total_samples = len(oni_series) - SEQ_LEN - N_LEADS\n",
                "train_size = int(0.7 * total_samples)\n",
                "val_size = int(0.15 * total_samples)\n",
                "test_size = total_samples - train_size - val_size\n",
                "\n",
                "train_end = train_size + SEQ_LEN + N_LEADS\n",
                "val_start = train_size\n",
                "val_end = val_start + val_size + SEQ_LEN + N_LEADS\n",
                "test_start = val_start + val_size\n",
                "\n",
                "train_dataset = ONIDataset(oni_series[:train_end], labels[:train_end], SEQ_LEN, N_LEADS)\n",
                "val_dataset = ONIDataset(oni_series[val_start:val_end], labels[val_start:val_end], SEQ_LEN, N_LEADS)\n",
                "test_dataset = ONIDataset(oni_series[test_start:], labels[test_start:], SEQ_LEN, N_LEADS)\n",
                "\n",
                "BATCH_SIZE = 32\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
                "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
                "\n",
                "print(f\"Train samples: {len(train_dataset)}\")\n",
                "print(f\"Val samples:   {len(val_dataset)}\")\n",
                "print(f\"Test samples:  {len(test_dataset)}\")\n",
                "print(f\"\\nSample input shape: {train_dataset[0][0].shape}  (12 months of ONI)\")\n",
                "print(f\"Sample target: {train_dataset[0][1]}  (ENSO class at leads 1,2,3)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Models\n",
                "\n",
                "We compare three architectures on the 1D ONI sequence:\n",
                "\n",
                "1. **Linear**: Simplest baseline\n",
                "2. **MLP**: Feedforward network that can learn non-linear patterns\n",
                "3. **CNN**: 1D Convolutional network"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class LinearModel(nn.Module):\n",
                "    def __init__(self, seq_len, n_classes=3, n_leads=3):\n",
                "        super().__init__()\n",
                "        self.heads = nn.ModuleList([nn.Linear(seq_len, n_classes) for _ in range(n_leads)])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return tuple(head(x) for head in self.heads)\n",
                "\n",
                "\n",
                "class MLPModel(nn.Module):\n",
                "    def __init__(self, seq_len, hidden=64, n_classes=3, n_leads=3):\n",
                "        super().__init__()\n",
                "        self.backbone = nn.Sequential(\n",
                "            nn.Linear(seq_len, hidden),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(hidden, 32),\n",
                "            nn.ReLU(),\n",
                "        )\n",
                "        self.heads = nn.ModuleList([nn.Linear(32, n_classes) for _ in range(n_leads)])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        features = self.backbone(x)\n",
                "        return tuple(head(features) for head in self.heads)\n",
                "\n",
                "\n",
                "class CNN1DModel(nn.Module):\n",
                "    def __init__(self, seq_len, n_classes=3, n_leads=3):\n",
                "        super().__init__()\n",
                "        # Input: (Batch, 1, Seq_Len) -> simple 1D Conv\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool1d(kernel_size=2),\n",
                "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool1d(kernel_size=2),\n",
                "            nn.Flatten()\n",
                "        )\n",
                "        \n",
                "        self.flatten_dim = 32 * (seq_len // 4) \n",
                "        \n",
                "        self.heads = nn.ModuleList([nn.Linear(self.flatten_dim, n_classes) for _ in range(n_leads)])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = x.unsqueeze(1)\n",
                "        x = self.features(x)\n",
                "        return tuple(head(x) for head in self.heads)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training with PyTorch Lightning\n",
                "\n",
                "The total loss is the sum of Cross-Entropy losses across all three lead times. We use Early Stopping to prevent overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ENSOPredictor(pl.LightningModule):\n",
                "    def __init__(self, model, learning_rate=0.001):\n",
                "        super().__init__()\n",
                "        self.model = model\n",
                "        self.lr = learning_rate\n",
                "        self.criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.model(x)\n",
                "\n",
                "    def _compute_loss(self, batch):\n",
                "        x, y = batch\n",
                "        outputs = self(x)\n",
                "        loss = sum(self.criterion(outputs[i], y[:, i]) for i in range(len(outputs)))\n",
                "        return loss\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        loss = self._compute_loss(batch)\n",
                "        self.log(\"train_loss\", loss, prog_bar=True)\n",
                "        return loss\n",
                "\n",
                "    def validation_step(self, batch, batch_idx):\n",
                "        loss = self._compute_loss(batch)\n",
                "        self.log(\"val_loss\", loss, prog_bar=True)\n",
                "        return loss\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return optim.Adam(self.parameters(), lr=self.lr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.1 Linear Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "linear_model = LinearModel(SEQ_LEN)\n",
                "pl_linear = ENSOPredictor(linear_model)\n",
                "\n",
                "early_stop = EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=False)\n",
                "\n",
                "trainer_linear = pl.Trainer(\n",
                "    max_epochs=50,\n",
                "    callbacks=[early_stop],\n",
                "    enable_progress_bar=True,\n",
                "    logger=False,\n",
                "    enable_checkpointing=False\n",
                ")\n",
                "\n",
                "trainer_linear.fit(pl_linear, train_loader, val_loader)\n",
                "trained_models = {}\n",
                "results = {}\n",
                "trained_models['Linear'] = linear_model\n",
                "\n",
                "# Evaluate\n",
                "linear_model.eval()\n",
                "correct = [0, 0, 0]\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        outputs = linear_model(data)\n",
                "        total += data.size(0)\n",
                "        for i in range(3):\n",
                "            _, predicted = torch.max(outputs[i], 1)\n",
                "            correct[i] += (predicted == target[:, i]).sum().item()\n",
                "\n",
                "accs = [100 * c / total for c in correct]\n",
                "results['Linear'] = accs\n",
                "print(f\"Linear Results: Lead 1: {accs[0]:.1f}% | Lead 2: {accs[1]:.1f}% | Lead 3: {accs[2]:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.2 MLP Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mlp_model = MLPModel(SEQ_LEN)\n",
                "pl_mlp = ENSOPredictor(mlp_model)\n",
                "\n",
                "early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=False)\n",
                "\n",
                "trainer_mlp = pl.Trainer(\n",
                "    max_epochs=200,\n",
                "    callbacks=[early_stop],\n",
                "    enable_progress_bar=True,\n",
                "    logger=False,\n",
                "    enable_checkpointing=False\n",
                ")\n",
                "\n",
                "trainer_mlp.fit(pl_mlp, train_loader, val_loader)\n",
                "trained_models['MLP'] = mlp_model\n",
                "\n",
                "# Evaluate\n",
                "mlp_model.eval()\n",
                "correct = [0, 0, 0]\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        outputs = mlp_model(data)\n",
                "        total += data.size(0)\n",
                "        for i in range(3):\n",
                "            _, predicted = torch.max(outputs[i], 1)\n",
                "            correct[i] += (predicted == target[:, i]).sum().item()\n",
                "\n",
                "accs = [100 * c / total for c in correct]\n",
                "results['MLP'] = accs\n",
                "print(f\"MLP Results: Lead 1: {accs[0]:.1f}% | Lead 2: {accs[1]:.1f}% | Lead 3: {accs[2]:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 7.3 CNN 1D Model\n",
                "\n",
                "![cnn1d](imgs/Conv1D.gif)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "cnn_model = CNN1DModel(SEQ_LEN)\n",
                "pl_cnn = ENSOPredictor(cnn_model)\n",
                "\n",
                "early_stop = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=False)\n",
                "\n",
                "trainer_cnn = pl.Trainer(\n",
                "    max_epochs=200,\n",
                "    callbacks=[early_stop],\n",
                "    enable_progress_bar=True,\n",
                "    logger=False,\n",
                "    enable_checkpointing=False\n",
                ")\n",
                "\n",
                "trainer_cnn.fit(pl_cnn, train_loader, val_loader)\n",
                "trained_models['CNN'] = cnn_model\n",
                "\n",
                "# Evaluate\n",
                "cnn_model.eval()\n",
                "correct = [0, 0, 0]\n",
                "total = 0\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        outputs = cnn_model(data)\n",
                "        total += data.size(0)\n",
                "        for i in range(3):\n",
                "            _, predicted = torch.max(outputs[i], 1)\n",
                "            correct[i] += (predicted == target[:, i]).sum().item()\n",
                "\n",
                "accs = [100 * c / total for c in correct]\n",
                "results['CNN'] = accs\n",
                "print(f\"CNN Results: Lead 1: {accs[0]:.1f}% | Lead 2: {accs[1]:.1f}% | Lead 3: {accs[2]:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Results Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
                "colors = ['gray', 'blue', 'green']\n",
                "lead_names = ['1-month lead', '2-month lead', '3-month lead']\n",
                "\n",
                "for i, ax in enumerate(axes):\n",
                "    model_names = list(results.keys())\n",
                "    accs = [results[name][i] for name in model_names]\n",
                "    bars = ax.bar(model_names, accs, color=colors)\n",
                "    ax.axhline(33.3, color='red', linestyle='--', alpha=0.5, label='Random (33%)')\n",
                "    ax.set_title(lead_names[i])\n",
                "    ax.set_ylabel('Accuracy (%)' if i == 0 else '')\n",
                "    ax.set_ylim(0, 100)\n",
                "    ax.legend()\n",
                "    for bar, acc in zip(bars, accs):\n",
                "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
                "                f'{acc:.1f}%', ha='center', va='bottom', fontsize=10)\n",
                "\n",
                "plt.suptitle('ENSO Phase Prediction: Model Comparison', fontsize=14)\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrices for the best model\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "\n",
                "best_name = max(results, key=lambda k: sum(results[k]))\n",
                "best_model = trained_models[best_name]\n",
                "print(f\"Best model: {best_name}\")\n",
                "\n",
                "best_model.eval()\n",
                "all_preds = [[], [], []]\n",
                "all_targets = [[], [], []]\n",
                "\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        outputs = best_model(data)\n",
                "        for i in range(3):\n",
                "            _, predicted = torch.max(outputs[i], 1)\n",
                "            all_preds[i].extend(predicted.numpy())\n",
                "            all_targets[i].extend(target[:, i].numpy())\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
                "for i, ax in enumerate(axes):\n",
                "    cm = confusion_matrix(all_targets[i], all_preds[i], labels=[0, 1, 2])\n",
                "    disp = ConfusionMatrixDisplay(cm, display_labels=phase_names)\n",
                "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
                "    ax.set_title(f\"Lead {i+1} ({lead_names[i]})\")\n",
                "\n",
                "plt.suptitle(f'Confusion Matrices: {best_name}', fontsize=14)\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Live Forecast\n",
                "\n",
                "Let's use the last 12 months of our ONI time series to predict ENSO for the upcoming months."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the last 12 months of ONI as input\n",
                "last_12 = oni_series[-SEQ_LEN:]\n",
                "last_date = oni_series.index[-1]\n",
                "\n",
                "print(f\"Input: ONI from {oni_series.index[-SEQ_LEN].strftime('%Y-%m')} to {last_date.strftime('%Y-%m')}\")\n",
                "print(f\"Last 12 ONI values: {np.round(last_12, 2)}\")\n",
                "\n",
                "# Predict\n",
                "best_model.eval()\n",
                "with torch.no_grad():\n",
                "    inp = torch.tensor(last_12.values, dtype=torch.float32).unsqueeze(0)\n",
                "    outputs = best_model(inp)\n",
                "\n",
                "# Display forecast\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"ENSO Forecast (from {best_name} model)\")\n",
                "print(f\"{'='*50}\")\n",
                "\n",
                "for i in range(N_LEADS):\n",
                "    probs = torch.softmax(outputs[i], dim=1)[0]\n",
                "    pred_class = outputs[i].argmax().item()\n",
                "    forecast_month = last_date + pd.DateOffset(months=i+1)\n",
                "    print(f\"\\n  {forecast_month.strftime('%B %Y')}:\")\n",
                "    for j, name in enumerate(phase_names):\n",
                "        marker = \" ◀\" if j == pred_class else \"\"\n",
                "        print(f\"    {name}: {probs[j]:.1%}{marker}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Discussion\n",
                "\n",
                "### Key Takeaways\n",
                "- **ONI as a feature**: The ONI time series captures the essential ENSO signal. A single number per month computed from gridded SST data\n",
                "- **Sequence -> Classification**: Framing ENSO prediction as classification avoids the difficulties of exact regression\n",
                "- **Lead time decay**: Accuracy decreases with longer lead times\n",
                "- **Real-world impact**: ENSO forecasts inform agriculture, disaster preparedness, and water resource management worldwide\n",
                "\n",
                "### Next Steps\n",
                "- Use the **full 2D SST maps** instead of just ONI (needs a 2D CNN, more powerful but more complex)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. From 1D to 2D: SST as a predictor\n",
                "\n",
                "We now advance to using the full **Sea Surface Temperature (SST) maps** as input, rather than just the simplified ONI index.\n",
                "\n",
                "We will compare two approaches:\n",
                "1.  **2D CNN Classifier**: Takes the sequence of 12 SST maps and directly predicts the ENSO class (0, 1, 2).\n",
                "2.  **U-Net Map Predictor**: Takes the sequence of 12 SST maps and predicts the **Next Month's SST Map**. We then calculate the ONI from the predicted map to determine the ENSO Phase."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SST Dataset for 2D Maps\n",
                "class SSTDataset(Dataset):\n",
                "    def __init__(self, sst_data, labels, seq_len=12, n_leads=3):\n",
                "        self.seq_len = seq_len\n",
                "        self.n_leads = n_leads\n",
                "        # Fill NaNs with 0.0 (Land)\n",
                "        self.sst_data = torch.tensor(np.nan_to_num(sst_data), dtype=torch.float32)\n",
                "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
                "\n",
                "    def __len__(self):\n",
                "        max_idx_sst = len(self.sst_data) - self.seq_len - self.n_leads\n",
                "        max_idx_labels = len(self.labels) - self.seq_len - self.n_leads\n",
                "        max_idx = min(max_idx_sst, max_idx_labels)\n",
                "        return max(0, max_idx + 1)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        # Input: (Seq_Len, Lat, Lon)\n",
                "        x = self.sst_data[idx : idx + self.seq_len]\n",
                "        \n",
                "        # Target Class: (n_leads)\n",
                "        target_start = idx + self.seq_len\n",
                "        target_end = target_start + self.n_leads\n",
                "        y = self.labels[target_start : target_end]\n",
                "        \n",
                "        # if len(y) < self.n_leads:\n",
                "        #     padding = torch.full((self.n_leads - len(y),), y[-1] if len(y)>0 else 0, dtype=torch.long)\n",
                "        #     y = torch.cat([y, padding])\n",
                "        \n",
                "        # Target Map Sequence: (n_leads, Lat, Lon)\n",
                "        y_map = self.sst_data[target_start : target_end]\n",
                "        \n",
                "        # Safety check for map\n",
                "        if len(y_map) < self.n_leads:\n",
                "             # Pad with last frame\n",
                "             pad_frames = self.n_leads - len(y_map)\n",
                "             last_frame = y_map[-1].unsqueeze(0) if len(y_map) > 0 else torch.zeros(1, *self.sst_data.shape[1:])\n",
                "             padding = last_frame.repeat(pad_frames, 1, 1)\n",
                "             y_map = torch.cat([y_map, padding])\n",
                "        \n",
                "        return x, y, y_map\n",
                "\n",
                "sst_values = ds.ssta.values\n",
                "train_dataset_2d = SSTDataset(sst_values[:train_end], labels[:train_end], SEQ_LEN, N_LEADS)\n",
                "val_dataset_2d = SSTDataset(sst_values[val_start:val_end], labels[val_start:val_end], SEQ_LEN, N_LEADS)\n",
                "test_dataset_2d = SSTDataset(sst_values[test_start:], labels[test_start:], SEQ_LEN, N_LEADS)\n",
                "\n",
                "train_loader_2d = DataLoader(train_dataset_2d, batch_size=16, shuffle=True)\n",
                "val_loader_2d = DataLoader(val_dataset_2d, batch_size=16)\n",
                "test_loader_2d = DataLoader(test_dataset_2d, batch_size=16)\n",
                "\n",
                "print(f\"2D Sample Shape: {train_dataset_2d[0][0].shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 11.1 2D CNN Classifier\n",
                "\n",
                "![cnn](imgs/cnn2d.jpg)\n",
                "\n",
                "Convolutional Neural Networks (CNNs) are deep learning models specialized for processing grid-like data (e.g., images). Unlike standard networks that flatten input immediately, CNNs preserve spatial structure to detect patterns like edges and shapes.\n",
                "\n",
                "#### **Key Components**\n",
                "\n",
                "1. **Convolutional Layers:** Slide small filters (kernels) across the image to extract features. This allows the model to learn patterns regardless of their position.\n",
                "2. **Pooling Layers:** Downsample the image (e.g., Max Pooling) to reduce dimensions and computational cost.\n",
                "3. **Fully Connected Layers:** Standard dense layers at the end that use the extracted features to make a final prediction.\n",
                "\n",
                "![conv](imgs/same_padding_no_strides.gif)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class CNN2DModel(nn.Module):\n",
                "    def __init__(self, seq_len, lat_dim, lon_dim, n_classes=3, n_leads=3, dense_hidden=128):\n",
                "        super().__init__()\n",
                "        # Input: (Batch, Seq_Len, Lat, Lon) -> Treat Seq_Len as Channels\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(seq_len, 16, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
                "            nn.ReLU(),\n",
                "            nn.MaxPool2d(2),\n",
                "            nn.Flatten()\n",
                "        )\n",
                "        \n",
                "        with torch.no_grad():\n",
                "            dummy = torch.zeros(1, seq_len, lat_dim, lon_dim)\n",
                "            out = self.features(dummy)\n",
                "            self.flat_dim = out.shape[1]\n",
                "            \n",
                "        # Enhanced Fully Connected Block\n",
                "        self.fc_block = nn.Sequential(\n",
                "            nn.Linear(self.flat_dim, dense_hidden),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3),\n",
                "            nn.Linear(dense_hidden, dense_hidden // 2),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3)\n",
                "        )\n",
                "        \n",
                "        # Heads take input from the last FC layer\n",
                "        self.heads = nn.ModuleList([nn.Linear(dense_hidden // 2, n_classes) for _ in range(n_leads)])\n",
                "        \n",
                "    def forward(self, x):\n",
                "        x = self.features(x)\n",
                "        x = self.fc_block(x)\n",
                "        return tuple(head(x) for head in self.heads)\n",
                "\n",
                "lat_dim = len(ds.lat)\n",
                "lon_dim = len(ds.lon)\n",
                "\n",
                "cnn2d = CNN2DModel(SEQ_LEN, lat_dim, lon_dim)\n",
                "pl_cnn2d = ENSOPredictor(cnn2d)\n",
                "\n",
                "class ENSO2DClassifier(ENSOPredictor):\n",
                "    def _compute_loss(self, batch):\n",
                "        x, y, _ = batch # Ignore y_map\n",
                "        outputs = self(x)\n",
                "        loss = sum(self.criterion(outputs[i], y[:, i]) for i in range(len(outputs)))\n",
                "        return loss\n",
                "\n",
                "pl_cnn2d = ENSO2DClassifier(cnn2d)\n",
                "\n",
                "early_stop_2d = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=False)\n",
                "trainer_2d = pl.Trainer(max_epochs=200, callbacks=[early_stop_2d], enable_progress_bar=True, check_val_every_n_epoch=2)\n",
                "trainer_2d.fit(pl_cnn2d, train_loader_2d, val_loader_2d)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 11.2 U-Net Classifier (Map -> Class)\n",
                "\n",
                "![unet](imgs/unet.jpg)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class UNetClassifier(nn.Module):\n",
                "    def __init__(self, in_channels, n_classes=3, n_leads=3, dense_hidden=64):\n",
                "        super().__init__()\n",
                "\n",
                "        def conv_block(in_c, out_c):\n",
                "            return nn.Sequential(\n",
                "                nn.Conv2d(in_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(),\n",
                "                nn.Conv2d(out_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU()\n",
                "            )\n",
                "\n",
                "        # Encoder\n",
                "        self.enc1 = conv_block(in_channels, 32)\n",
                "        self.pool1 = nn.MaxPool2d(2)\n",
                "        self.enc2 = conv_block(32, 64)\n",
                "        self.pool2 = nn.MaxPool2d(2)\n",
                "        \n",
                "        # Bottleneck\n",
                "        self.bottleneck = conv_block(64, 128)\n",
                "        \n",
                "        # Decoder\n",
                "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
                "        self.dec2 = conv_block(128, 64)\n",
                "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
                "        self.dec1 = conv_block(64, 32)\n",
                "        \n",
                "        # Classification Head\n",
                "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
                "        \n",
                "        self.fc_block = nn.Sequential(\n",
                "            nn.Linear(32, dense_hidden),\n",
                "            nn.ReLU(),\n",
                "            nn.Dropout(0.3)\n",
                "        )\n",
                "        \n",
                "        self.heads = nn.ModuleList([nn.Linear(dense_hidden, n_classes) for _ in range(n_leads)])\n",
                "\n",
                "    def forward(self, x):\n",
                "        e1 = self.enc1(x)\n",
                "        p1 = self.pool1(e1)\n",
                "        e2 = self.enc2(p1)\n",
                "        p2 = self.pool2(e2)\n",
                "        \n",
                "        b = self.bottleneck(p2)\n",
                "        \n",
                "        d2 = self.up2(b)\n",
                "        if d2.shape != e2.shape: d2 = nn.functional.interpolate(d2, size=e2.shape[2:])\n",
                "        d2 = torch.cat((d2, e2), dim=1)\n",
                "        d2 = self.dec2(d2)\n",
                "        \n",
                "        d1 = self.up1(d2)\n",
                "        if d1.shape != e1.shape: d1 = nn.functional.interpolate(d1, size=e1.shape[2:])\n",
                "        d1 = torch.cat((d1, e1), dim=1)\n",
                "        d1 = self.dec1(d1)\n",
                "        \n",
                "        # Classification Branch\n",
                "        out = self.global_pool(d1)\n",
                "        out = out.view(out.size(0), -1)\n",
                "        out = self.fc_block(out)\n",
                "        \n",
                "        return tuple(head(out) for head in self.heads)\n",
                "\n",
                "# U-Net is now a Classifier, so we use CrossEntropy\n",
                "unet = UNetClassifier(in_channels=SEQ_LEN)\n",
                "pl_unet = ENSO2DClassifier(unet) \n",
                "\n",
                "early_stop_unet = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=False)\n",
                "trainer_unet = pl.Trainer(max_epochs=200, callbacks=[early_stop_unet], enable_progress_bar=True, check_val_every_n_epoch=2)\n",
                "trainer_unet.fit(pl_unet, train_loader_2d, val_loader_2d)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 11.3 Results Comparison (1D vs 2D Models)\n",
                "models_2d = {'CNN2D': cnn2d, 'UNet': unet}\n",
                "results_2d = {}\n",
                "\n",
                "print(\"Evaluating 2D Models...\")\n",
                "for name, model in models_2d.items():\n",
                "    model.eval()\n",
                "    correct = [0, 0, 0]\n",
                "    total = 0\n",
                "    with torch.no_grad():\n",
                "        for data, target, _ in test_loader_2d: # Ignore y_map\n",
                "            outputs = model(data)\n",
                "            total += data.size(0)\n",
                "            for i in range(3):\n",
                "                _, predicted = torch.max(outputs[i], 1)\n",
                "                correct[i] += (predicted == target[:, i]).sum().item()\n",
                "    \n",
                "    accs = [100 * c / total for c in correct]\n",
                "    results_2d[name] = accs\n",
                "    print(f\"{name} Results: Lead 1: {accs[0]:.1f}% | Lead 2: {accs[1]:.1f}% | Lead 3: {accs[2]:.1f}%\")\n",
                "\n",
                "# Plot Comparison\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
                "lead_names = ['Lead 1 Month', 'Lead 2 Months', 'Lead 3 Months']\n",
                "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd'] # Blue, Orange, Green, Red, Purple\n",
                "\n",
                "# Combine 1D results if available\n",
                "all_results = results.copy() if 'results' in locals() else {}\n",
                "all_results.update(results_2d)\n",
                "\n",
                "model_names = list(all_results.keys())\n",
                "\n",
                "for i, ax in enumerate(axes):\n",
                "    accuracies = [all_results[m][i] for m in model_names]\n",
                "    bars = ax.bar(model_names, accuracies, color=colors[:len(model_names)])\n",
                "    ax.set_title(lead_names[i])\n",
                "    ax.set_ylim(0, 100)\n",
                "    ax.axhline(33.3, color='grey', linestyle='--', label='Random Chance')\n",
                "    ax.legend()\n",
                "    \n",
                "    # Add labels\n",
                "    for bar, acc in zip(bars, accuracies):\n",
                "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
                "                f'{acc:.1f}%', ha='center', va='bottom')\n",
                "\n",
                "plt.suptitle(\"ENSO Prediction Accuracy: 1D (ONI) vs 2D (SST Maps)\", fontsize=16)\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## U-Net for Next-Month SST Map Prediction\n",
                "\n",
                "In this section, we will implement a **U-Net** to predict the **Scale Sea Surface Temperature (SST)** map for the *next month* (Lead 1) based on the past 12 months of anomaly maps.\n",
                "\n",
                "We modify the problem from a sequence-to-sequence prediction (predicting 3 months) to a **Next-Step Prediction** (predicting 1 month). This simplification allows the model to focus on the immediate future evolution, potentially improving its skill.\n",
                "\n",
                "### 1. The U-Net Architecture\n",
                "We use a deeper U-Net architecture with 3 encoding steps, increasing the channel depth to 256 at the bottleneck. This allows the network to capture complex spatial patterns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create Land Mask (1 for Sea, 0 for Land/NaN)\n",
                "# We use the first time step of the dataset to identify NaN regions\n",
                "land_mask_xr = ds['sst'].isel(time=0).notnull()\n",
                "land_mask = torch.tensor(land_mask_xr.values, dtype=torch.float32)\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(10, 4))\n",
                "im = land_mask_xr.plot(\n",
                "    ax=ax, \n",
                "    cmap='gray', \n",
                "    add_colorbar=True,\n",
                "    cbar_kwargs={'label': 'Mask Value'}\n",
                ")\n",
                "\n",
                "ax.set_title(\"Valid Ocean Mask (White=Sea, Black=Land)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class UNetMapModel(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels=1): # Output 1 channel (Next Month)\n",
                "        super().__init__()\n",
                "\n",
                "        def conv_block(in_c, out_c):\n",
                "            return nn.Sequential(\n",
                "                nn.Conv2d(in_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(),\n",
                "                nn.Conv2d(out_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU()\n",
                "            )\n",
                "\n",
                "        # Encoder\n",
                "        self.enc1 = conv_block(in_channels, 32)\n",
                "        self.pool1 = nn.MaxPool2d(2)\n",
                "        self.enc2 = conv_block(32, 64)\n",
                "        self.pool2 = nn.MaxPool2d(2)\n",
                "        self.enc3 = conv_block(64, 128)\n",
                "        self.pool3 = nn.MaxPool2d(2)\n",
                "        \n",
                "        # Bottleneck\n",
                "        self.bottleneck = conv_block(128, 256)\n",
                "        \n",
                "        # Decoder\n",
                "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
                "        self.dec3 = conv_block(256, 128)\n",
                "        \n",
                "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
                "        self.dec2 = conv_block(128, 64)\n",
                "        \n",
                "        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)\n",
                "        self.dec1 = conv_block(64, 32)\n",
                "        \n",
                "        self.final = nn.Conv2d(32, out_channels, 1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        e1 = self.enc1(x)\n",
                "        p1 = self.pool1(e1)\n",
                "        e2 = self.enc2(p1)\n",
                "        p2 = self.pool2(e2)\n",
                "        e3 = self.enc3(p2)\n",
                "        p3 = self.pool3(e3)\n",
                "        \n",
                "        b = self.bottleneck(p3)\n",
                "        \n",
                "        d3 = self.up3(b)\n",
                "        if d3.shape != e3.shape: d3 = nn.functional.interpolate(d3, size=e3.shape[2:])\n",
                "        d3 = torch.cat((d3, e3), dim=1)\n",
                "        d3 = self.dec3(d3)\n",
                "        \n",
                "        d2 = self.up2(d3)\n",
                "        if d2.shape != e2.shape: d2 = nn.functional.interpolate(d2, size=e2.shape[2:])\n",
                "        d2 = torch.cat((d2, e2), dim=1)\n",
                "        d2 = self.dec2(d2)\n",
                "        \n",
                "        d1 = self.up1(d2)\n",
                "        if d1.shape != e1.shape: d1 = nn.functional.interpolate(d1, size=e1.shape[2:])\n",
                "        d1 = torch.cat((d1, e1), dim=1)\n",
                "        d1 = self.dec1(d1)\n",
                "        \n",
                "        return self.final(d1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. PyTorch Lightning Module\n",
                "We wrap the U-Net model with PyTorch Lightning to handle training loops, optimization, and logging."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SSTMapPredictor(pl.LightningModule):\n",
                "    def __init__(self, model, mask, lr=1e-3):\n",
                "        super().__init__()\n",
                "        self.model = model\n",
                "        self.register_buffer('mask', mask) # Mask moves to GPU with model\n",
                "        self.lr = lr\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.model(x)\n",
                "    \n",
                "    def masked_mse_loss(self, pred, target):\n",
                "        # Squared Error\n",
                "        sq_error = (pred - target) ** 2\n",
                "        # Mask out land pixels\n",
                "        masked_error = sq_error * self.mask\n",
                "        # Mean only over valid pixels\n",
                "        loss = masked_error.sum() / self.mask.sum() / pred.shape[0] # Divide by batch size too\n",
                "        return loss\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        x, _, y_seq = batch\n",
                "        y_target = y_seq[:, 0, :, :].unsqueeze(1) \n",
                "        pred_map = self(x)\n",
                "        loss = self.masked_mse_loss(pred_map, y_target)\n",
                "        self.log(\"train_mse\", loss, prog_bar=True)\n",
                "        return loss\n",
                "\n",
                "    def validation_step(self, batch, batch_idx):\n",
                "        x, _, y_seq = batch\n",
                "        y_target = y_seq[:, 0, :, :].unsqueeze(1)\n",
                "        pred_map = self(x)\n",
                "        loss = self.masked_mse_loss(pred_map, y_target)\n",
                "        self.log(\"val_mse\", loss, prog_bar=True)\n",
                "        return loss\n",
                "        \n",
                "    def configure_optimizers(self):\n",
                "        return optim.Adam(self.parameters(), lr=self.lr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3. Training the Model\n",
                "We initialize the model with `out_channels=1` and train using the standard PyTorch Lightning Trainer with Early Stopping."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "unet_map = UNetMapModel(in_channels=SEQ_LEN, out_channels=1) \n",
                "pl_unet_map = SSTMapPredictor(unet_map, mask=land_mask)\n",
                "\n",
                "early_stop_map = EarlyStopping(monitor='val_mse', patience=10, mode='min', verbose=False)\n",
                "trainer_map = pl.Trainer(max_epochs=200, callbacks=[early_stop_map], enable_progress_bar=True, check_val_every_n_epoch=2)\n",
                "trainer_map.fit(pl_unet_map, train_loader_2d, val_loader_2d)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import cartopy.crs as ccrs\n",
                "import cartopy.feature as cfeature\n",
                "\n",
                "pl_unet_map.eval()\n",
                "test_sample_idx = 0\n",
                "\n",
                "with torch.no_grad():\n",
                "    x, _, y_seq = test_dataset_2d[test_sample_idx]\n",
                "    # x: (12, Lat, Lon), y_seq: (3, Lat, ]\n",
                "    pred_map = pl_unet_map(x.unsqueeze(0)).squeeze(0).squeeze(0) # (Lat, Lon)\n",
                "    target_map = y_seq[0] # Next Month (Lead 1)\n",
                "\n",
                "# Setup Projection\n",
                "proj = ccrs.PlateCarree(central_longitude=180)\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5), subplot_kw={'projection': proj})\n",
                "\n",
                "def plot_sst(ax, data_tensor, title):\n",
                "    da = xr.DataArray(data_tensor.numpy(), coords={'lat': ds.lat, 'lon': ds.lon}, dims=('lat', 'lon'))\n",
                "    im = da.plot(ax=ax, transform=ccrs.PlateCarree(), \n",
                "                 cmap='RdBu_r', vmin=-2.5, vmax=2.5, add_colorbar=False)\n",
                "    ax.add_feature(cfeature.COASTLINE, linewidth=0.8)\n",
                "    ax.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.6)\n",
                "    ax.gridlines(draw_labels=False, linewidth=0.5, color='gray', alpha=0.5)\n",
                "    ax.set_title(title, fontsize=12)\n",
                "    return im\n",
                "\n",
                "# 1. Input (Last Month)\n",
                "plot_sst(axes[0], x[-1], \"Input: Last Month (T-0)\")\n",
                "\n",
                "# 2. Target (Next Month)\n",
                "plot_sst(axes[1], target_map, \"Target: Next Month (Lead 1)\")\n",
                "\n",
                "# 3. Prediction\n",
                "im = plot_sst(axes[2], pred_map, \"Prediction: Next Month (Lead 1)\")\n",
                "\n",
                "# Colorbar\n",
                "cbar_ax = fig.add_axes([0.92, 0.2, 0.02, 0.6])\n",
                "cbar = fig.colorbar(im, cax=cbar_ax, label='SST Anomaly (°C)')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hidsi_wxclim",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
