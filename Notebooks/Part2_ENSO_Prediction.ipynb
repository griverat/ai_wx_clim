{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: ENSO Phase Prediction\n",
                "\n",
                "**Goal**: Predict the ENSO phase (Neutral / El Niño / La Niña) 1–3 months ahead using the ONI computed from ERSSTv6 data.\n",
                "\n",
                "## 1. What is ENSO?\n",
                "\n",
                "![enso](imgs/enso.png)\n",
                "\n",
                "The **El Niño–Southern Oscillation (ENSO)** is a climate phenomenon in the Pacific Ocean characterized by periodic warming and cooling of sea surface temperatures.\n",
                "\n",
                "- **El Niño**: Warmer-than-average SSTs in the central/eastern equatorial Pacific -> droughts in Australia/SE Asia, flooding in South America, warmer winters in North America.\n",
                "- **La Niña**: Cooler-than-average SSTs in the same region -> opposite effects.\n",
                "- **Neutral**: Near-average conditions.\n",
                "\n",
                "ENSO is one of the most important drivers of global climate variability. Predicting it months in advance is a major challenge.\n",
                "\n",
                "### The Oceanic Niño Index (ONI)\n",
                "The **ONI** is the standard metric for ENSO monitoring. It is computed as:\n",
                "1. Average SST anomalies over the **Niño 3.4 region** (5°S–5°N, 170°W–120°W)\n",
                "2. Apply a **3-month centered running mean** to smooth out noise\n",
                "\n",
                "ENSO phase is then defined by thresholds on ONI:\n",
                "- **El Niño**: ONI ≥ +0.5°C\n",
                "- **La Niña**: ONI ≤ −0.5°C\n",
                "- **Neutral**: −0.5°C < ONI < +0.5°C\n",
                "\n",
                "### Our Task\n",
                "Given the **last 12 months of ONI values**, predict the **ENSO class** for each of the **next 3 months**. This is a **sequence -> classification** problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import xarray as xr\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning.callbacks import EarlyStopping\n",
                "\n",
                "device = torch.device(\n",
                "    \"cuda\" if torch.cuda.is_available()\n",
                "    else \"mps\" if torch.backends.mps.is_available()\n",
                "    else \"cpu\"\n",
                ")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load ERSSTv6 Data\n",
                "\n",
                "We load the combined dataset that was prepared in Part 2A."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds = xr.open_dataset(\"../data/processed/ersstv6_combined.nc\")\n",
                "print(f\"Time: {str(ds.time.values[0])[:7]} to {str(ds.time.values[-1])[:7]} ({len(ds.time)} months)\")\n",
                "print(f\"Grid: {len(ds.lat)} lat × {len(ds.lon)} lon\")\n",
                "print(f\"Variables: {list(ds.data_vars)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compute the Oceanic Niño Index (ONI)\n",
                "\n",
                "The ONI is computed in two steps:\n",
                "1. **Spatial average**: Area-weighted mean SSTA over the Niño 3.4 box (5°S–5°N, 170°W–120°W)\n",
                "2. **Temporal smoothing**: 3-month centered running mean"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Niño 3.4 region: 5°S-5°N, 170°W-120°W\n",
                "# In 0-360° longitude: 170°W = 190°, 120°W = 240°\n",
                "nino34 = ds.ssta.sel(lat=slice(-5, 5), lon=slice(190, 240))\n",
                "\n",
                "# Step 1: Area-weighted spatial average\n",
                "weights = np.cos(np.deg2rad(nino34.lat))\n",
                "nino34_index = nino34.weighted(weights).mean(dim=['lat', 'lon'])\n",
                "\n",
                "# Step 2: 3-month centered running mean → ONI\n",
                "oni = nino34_index.rolling(time=3, center=True).mean().dropna('time')\n",
                "\n",
                "# Convert to pandas\n",
                "oni_series = oni.to_series()\n",
                "oni_series.name = 'ONI'\n",
                "\n",
                "print(f\"ONI time series: {len(oni_series)} months\")\n",
                "print(f\"Range: {oni_series.index[0].strftime('%Y-%m')} to {oni_series.index[-1].strftime('%Y-%m')}\")\n",
                "print(f\"Mean: {oni_series.mean():.3f}, Std: {oni_series.std():.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots(figsize=(15, 4))\n",
                "\n",
                "ax.fill_between(oni_series.index, oni_series.values, 0.5,\n",
                "                where=oni_series.values >= 0.5, color='red', alpha=0.4, label='El Niño')\n",
                "ax.fill_between(oni_series.index, oni_series.values, -0.5,\n",
                "                where=oni_series.values <= -0.5, color='blue', alpha=0.4, label='La Niña')\n",
                "ax.plot(oni_series.index, oni_series.values, color='black', linewidth=0.8)\n",
                "ax.axhline(0.5, color='red', linestyle='--', alpha=0.5)\n",
                "ax.axhline(-0.5, color='blue', linestyle='--', alpha=0.5)\n",
                "ax.axhline(0, color='gray', linewidth=0.5)\n",
                "\n",
                "ax.set_title('Oceanic Niño Index (ONI) — Computed from ERSSTv6')\n",
                "ax.set_ylabel('ONI (°C)')\n",
                "ax.set_xlabel('Year')\n",
                "ax.legend(loc='upper left')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Label Each Month by ENSO Phase\n",
                "\n",
                "Using the standard ONI thresholds:\n",
                "- **0 = Neutral**: −0.5 < ONI < 0.5\n",
                "- **1 = El Niño**: ONI ≥ 0.5\n",
                "- **2 = La Niña**: ONI ≤ −0.5"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Label each month\n",
                "def oni_to_label(val):\n",
                "    if val >= 0.5:\n",
                "        return 1  # El Niño\n",
                "    elif val <= -0.5:\n",
                "        return 2  # La Niña\n",
                "    else:\n",
                "        return 0  # Neutral\n",
                "\n",
                "labels = oni_series.apply(oni_to_label).values\n",
                "\n",
                "phase_names = ['Neutral', 'El Niño', 'La Niña']\n",
                "for i, name in enumerate(phase_names):\n",
                "    count = (labels == i).sum()\n",
                "    print(f\"  {name}: {count} months ({100*count/len(labels):.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Prepare Sequences & DataLoaders\n",
                "\n",
                "We create a sliding window dataset:\n",
                "- **Input**: 12 consecutive months of ONI values\n",
                "- **Target**: ENSO class at lead 1, 2, and 3 months ahead\n",
                "\n",
                "As in Part 1, we split **by time** (chrono cross-validation): first 80% for training, last 20% for testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEQ_LEN = 12  # 12 months of ONI history\n",
                "N_LEADS = 3   # predict 1, 2, 3 months ahead\n",
                "\n",
                "class ONIDataset(Dataset):\n",
                "    def __init__(self, oni_values, labels, seq_len=12, n_leads=3):\n",
                "        self.seq_len = seq_len\n",
                "        self.n_leads = n_leads\n",
                "        self.samples = []\n",
                "        self.targets = []\n",
                "        \n",
                "        for i in range(len(oni_values) - seq_len - n_leads):\n",
                "            x = oni_values[i : i + seq_len]\n",
                "            y = [labels[i + seq_len + lead] for lead in range(n_leads)]\n",
                "            self.samples.append(x)\n",
                "            self.targets.append(y)\n",
                "        \n",
                "        self.samples = torch.tensor(np.array(self.samples), dtype=torch.float32)\n",
                "        self.targets = torch.tensor(np.array(self.targets), dtype=torch.long)\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.samples)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        return self.samples[idx], self.targets[idx]\n",
                "\n",
                "# Prepare data\n",
                "oni_values = oni_series.values.astype(np.float32)\n",
                "\n",
                "# 80/20 chrono split\n",
                "total_samples = len(oni_values) - SEQ_LEN - N_LEADS\n",
                "train_size = int(0.8 * total_samples)\n",
                "\n",
                "train_end = train_size + SEQ_LEN + N_LEADS\n",
                "train_dataset = ONIDataset(oni_values[:train_end], labels[:train_end], SEQ_LEN, N_LEADS)\n",
                "test_dataset = ONIDataset(oni_values[train_size:], labels[train_size:], SEQ_LEN, N_LEADS)\n",
                "\n",
                "BATCH_SIZE = 32\n",
                "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
                "\n",
                "print(f\"Train samples: {len(train_dataset)}\")\n",
                "print(f\"Test samples:  {len(test_dataset)}\")\n",
                "print(f\"\\nSample input shape: {train_dataset[0][0].shape}  (12 months of ONI)\")\n",
                "print(f\"Sample target: {train_dataset[0][1]}  (ENSO class at leads 1,2,3)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Models\n",
                "\n",
                "We compare three architectures on the 1D ONI sequence:\n",
                "\n",
                "1. **Linear**: Simplest baseline — weighted sum of 12 ONI values → 3×3 outputs\n",
                "2. **MLP**: Feedforward network that can learn non-linear patterns\n",
                "3. **LSTM**: Recurrent network that explicitly models temporal order"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "N_CLASSES = 3\n",
                "\n",
                "class LinearModel(nn.Module):\n",
                "    def __init__(self, seq_len, n_classes=3, n_leads=3):\n",
                "        super().__init__()\n",
                "        self.heads = nn.ModuleList([nn.Linear(seq_len, n_classes) for _ in range(n_leads)])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        return tuple(head(x) for head in self.heads)\n",
                "\n",
                "\n",
                "class MLPModel(nn.Module):\n",
                "    def __init__(self, seq_len, hidden=64, n_classes=3, n_leads=3):\n",
                "        super().__init__()\n",
                "        self.backbone = nn.Sequential(\n",
                "            nn.Linear(seq_len, hidden),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(hidden, 32),\n",
                "            nn.ReLU(),\n",
                "        )\n",
                "        self.heads = nn.ModuleList([nn.Linear(32, n_classes) for _ in range(n_leads)])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        features = self.backbone(x)\n",
                "        return tuple(head(features) for head in self.heads)\n",
                "\n",
                "\n",
                "class LSTMModel(nn.Module):\n",
                "    def __init__(self, hidden=64, n_classes=3, n_leads=3):\n",
                "        super().__init__()\n",
                "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden, batch_first=True)\n",
                "        self.heads = nn.ModuleList([nn.Linear(hidden, n_classes) for _ in range(n_leads)])\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = x.unsqueeze(-1)\n",
                "        out, _ = self.lstm(x)\n",
                "        last = out[:, -1, :]\n",
                "        return tuple(head(last) for head in self.heads)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Training with PyTorch Lightning\n",
                "\n",
                "The total loss is the sum of Cross-Entropy losses across all three lead times. We use Early Stopping to prevent overfitting."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ENSOPredictor(pl.LightningModule):\n",
                "    def __init__(self, model, learning_rate=0.001):\n",
                "        super().__init__()\n",
                "        self.model = model\n",
                "        self.lr = learning_rate\n",
                "        self.criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.model(x)\n",
                "\n",
                "    def _compute_loss(self, batch):\n",
                "        x, y = batch\n",
                "        outputs = self(x)\n",
                "        loss = sum(self.criterion(outputs[i], y[:, i]) for i in range(len(outputs)))\n",
                "        return loss\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        loss = self._compute_loss(batch)\n",
                "        self.log(\"train_loss\", loss, prog_bar=True)\n",
                "        return loss\n",
                "\n",
                "    def validation_step(self, batch, batch_idx):\n",
                "        loss = self._compute_loss(batch)\n",
                "        self.log(\"val_loss\", loss, prog_bar=True)\n",
                "        return loss\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return optim.Adam(self.parameters(), lr=self.lr)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Train all models\n",
                "model_configs = {\n",
                "    'Linear': LinearModel(SEQ_LEN),\n",
                "    'MLP': MLPModel(SEQ_LEN),\n",
                "    'LSTM': LSTMModel(),\n",
                "}\n",
                "\n",
                "trained_models = {}\n",
                "results = {}\n",
                "\n",
                "for name, model_arch in model_configs.items():\n",
                "    print(f\"\\n{'='*50}\")\n",
                "    print(f\"Training {name}\")\n",
                "    print(f\"{'='*50}\")\n",
                "    \n",
                "    pl_model = ENSOPredictor(model_arch, learning_rate=0.001)\n",
                "    \n",
                "    early_stop = EarlyStopping(\n",
                "        monitor='train_loss',\n",
                "        patience=10,\n",
                "        mode='min',\n",
                "        verbose=False\n",
                "    )\n",
                "    \n",
                "    trainer = pl.Trainer(\n",
                "        max_epochs=100,\n",
                "        callbacks=[early_stop],\n",
                "        enable_progress_bar=True,\n",
                "        logger=False,\n",
                "        enable_checkpointing=False\n",
                "    )\n",
                "    \n",
                "    trainer.fit(pl_model, train_loader)\n",
                "    trained_models[name] = model_arch\n",
                "    \n",
                "    # Evaluate on test set\n",
                "    model_arch.eval()\n",
                "    correct = [0, 0, 0]\n",
                "    total = 0\n",
                "    with torch.no_grad():\n",
                "        for data, target in test_loader:\n",
                "            outputs = model_arch(data)\n",
                "            total += data.size(0)\n",
                "            for i in range(3):\n",
                "                _, predicted = torch.max(outputs[i], 1)\n",
                "                correct[i] += (predicted == target[:, i]).sum().item()\n",
                "    \n",
                "    accs = [100 * c / total for c in correct]\n",
                "    results[name] = accs\n",
                "    print(f\"  Lead 1: {accs[0]:.1f}%  |  Lead 2: {accs[1]:.1f}%  |  Lead 3: {accs[2]:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Results Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bar chart comparison\n",
                "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
                "colors = ['gray', 'blue', 'green']\n",
                "lead_names = ['1-month lead', '2-month lead', '3-month lead']\n",
                "\n",
                "for i, ax in enumerate(axes):\n",
                "    model_names = list(results.keys())\n",
                "    accs = [results[name][i] for name in model_names]\n",
                "    bars = ax.bar(model_names, accs, color=colors)\n",
                "    ax.axhline(33.3, color='red', linestyle='--', alpha=0.5, label='Random (33%)')\n",
                "    ax.set_title(lead_names[i])\n",
                "    ax.set_ylabel('Accuracy (%)' if i == 0 else '')\n",
                "    ax.set_ylim(0, 100)\n",
                "    ax.legend()\n",
                "    for bar, acc in zip(bars, accs):\n",
                "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
                "                f'{acc:.1f}%', ha='center', va='bottom', fontsize=10)\n",
                "\n",
                "plt.suptitle('ENSO Phase Prediction: Model Comparison', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Confusion matrices for the best model\n",
                "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
                "\n",
                "best_name = max(results, key=lambda k: sum(results[k]))\n",
                "best_model = trained_models[best_name]\n",
                "print(f\"Best model: {best_name}\")\n",
                "\n",
                "best_model.eval()\n",
                "all_preds = [[], [], []]\n",
                "all_targets = [[], [], []]\n",
                "\n",
                "with torch.no_grad():\n",
                "    for data, target in test_loader:\n",
                "        outputs = best_model(data)\n",
                "        for i in range(3):\n",
                "            _, predicted = torch.max(outputs[i], 1)\n",
                "            all_preds[i].extend(predicted.numpy())\n",
                "            all_targets[i].extend(target[:, i].numpy())\n",
                "\n",
                "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
                "for i, ax in enumerate(axes):\n",
                "    cm = confusion_matrix(all_targets[i], all_preds[i], labels=[0, 1, 2])\n",
                "    disp = ConfusionMatrixDisplay(cm, display_labels=phase_names)\n",
                "    disp.plot(ax=ax, cmap='Blues', colorbar=False)\n",
                "    ax.set_title(f\"Lead {i+1} ({lead_names[i]})\")\n",
                "\n",
                "plt.suptitle(f'Confusion Matrices: {best_name}', fontsize=14)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Live Forecast\n",
                "\n",
                "Let's use the last 12 months of our ONI time series to predict ENSO for the upcoming months."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use the last 12 months of ONI as input\n",
                "last_12 = oni_values[-SEQ_LEN:]\n",
                "last_date = oni_series.index[-1]\n",
                "\n",
                "print(f\"Input: ONI from {oni_series.index[-SEQ_LEN].strftime('%Y-%m')} to {last_date.strftime('%Y-%m')}\")\n",
                "print(f\"Last 12 ONI values: {np.round(last_12, 2)}\")\n",
                "\n",
                "# Predict\n",
                "best_model.eval()\n",
                "with torch.no_grad():\n",
                "    inp = torch.tensor(last_12, dtype=torch.float32).unsqueeze(0)\n",
                "    outputs = best_model(inp)\n",
                "\n",
                "# Display forecast\n",
                "print(f\"\\n{'='*50}\")\n",
                "print(f\"ENSO Forecast (from {best_name} model)\")\n",
                "print(f\"{'='*50}\")\n",
                "\n",
                "for i in range(N_LEADS):\n",
                "    probs = torch.softmax(outputs[i], dim=1)[0]\n",
                "    pred_class = outputs[i].argmax().item()\n",
                "    forecast_month = last_date + pd.DateOffset(months=i+1)\n",
                "    print(f\"\\n  {forecast_month.strftime('%B %Y')}:\")\n",
                "    for j, name in enumerate(phase_names):\n",
                "        marker = \" ◀\" if j == pred_class else \"\"\n",
                "        print(f\"    {name}: {probs[j]:.1%}{marker}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Discussion\n",
                "\n",
                "### Key Takeaways\n",
                "- **ONI as a feature**: The ONI time series captures the essential ENSO signal — a single number per month computed from gridded SST data\n",
                "- **Sequence → Classification**: Framing ENSO prediction as classification avoids the difficulties of exact regression\n",
                "- **Lead time decay**: Accuracy decreases with longer lead times — a fundamental limit of predictability\n",
                "- **Real-world impact**: ENSO forecasts inform agriculture, disaster preparedness, and water resource management worldwide\n",
                "\n",
                "### Next Steps\n",
                "- Use the **full 2D SST maps** instead of just ONI (needs a 2D CNN — more powerful but more complex)\n",
                "- Try **multi-month input sequences of SST maps** (3D: time × lat × lon)\n",
                "- Use **WeatherBench2** for a more sophisticated global weather prediction approach"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hidsi_wxclim",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
