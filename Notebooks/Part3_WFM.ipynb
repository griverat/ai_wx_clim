{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "b2e1a3a6",
            "metadata": {},
            "source": [
                "# Part 3: Weather Foundational Model with Prithvi WxC\n",
                "\n",
                "## Introduction\n",
                "\n",
                "In this part of the workshop, we will explore the concept of **Weather Foundational Models** and use a state-of-the-art model called **Prithvi WxC** for a downscaling task.\n",
                "\n",
                "### What is a Weather Foundational Model?\n",
                "\n",
                "A **Foundational Model** in the context of weather and climate is a large AI model trained on vast amounts of meteorological data (like ERA5 or MERRA-2 reanalysis data). Unlike traditional numerical weather prediction (NWP) models that solve complex physical equations, these AI models learn the underlying physics and patterns of the atmosphere directly from the data. They are designed to be:\n",
                "\n",
                "*   **General-purpose**: Once pre-trained, they can be fine-tuned for various downstream tasks such as forecasting, downscaling, or gravity wave parameterization.\n",
                "*   **Efficient**: Inference is typically much faster than running high-resolution physical simulations.\n",
                "\n",
                "### Prithvi WxC\n",
                "\n",
                "**Prithvi WxC** is a 2.3 billion parameter Foundational Model developed by IBM and NASA. It is based on a **Vision Transformer (ViT)** architecture with an encoder-decoder structure. It treats weather data as a sequence of tokens, allowing it to capture both local and global interactions in the atmosphere.\n",
                "\n",
                "### The Task: Downscaling\n",
                "\n",
                "**Downscaling** is the process of generating high-resolution weather data from low-resolution inputs. This is crucial for local impact assessments where we need detailed information (e.g., city-level temperature) that global models (with coarse grids like 50km or 100km) cannot provide.\n",
                "\n",
                "In this notebook, we will use a fine-tuned version of Prithvi WxC to downscale **2-meter Temperature (T2M)** from the MERRA-2 dataset, increasing its resolution by **6x**.\n",
                "\n",
                "### Acknowledgements\n",
                "\n",
                "This notebook is adapted from the examples provided in the [Granite WxC repository](https://github.com/IBM/granite-wxc/tree/main/examples/merra2_downscaling/notebooks).\n",
                "\n",
                "Let's get started!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation\n",
                "\n",
                "We need to install the `PrithviWxC` and `granitewxc` libraries, along with standard data handling libraries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "053677a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "except:\n",
                "    IN_COLAB = False\n",
                "\n",
                "if IN_COLAB:\n",
                "    print(\"Running on Google Colab. Installing dependencies...\")\n",
                "    !apt-get install -y libgeos-dev libproj-dev\n",
                "    !pip install h5netcdf matplotlib wget pyyaml xarray scipy torch PrithviWxC granitewxc huggingface_hub cartopy\n",
                "else:\n",
                "    print(\"Running locally. Skipping dependency installation.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0bd3cbc0",
            "metadata": {},
            "source": [
                "## 2. Imports and Configuration\n",
                "\n",
                "Import the necessary modules and set up the computing device (GPU is highly recommended)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6acec501",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import wget\n",
                "import random\n",
                "from pathlib import Path\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from itertools import product\n",
                "import numpy as np\n",
                "import torch\n",
                "from torch.utils.data import DataLoader\n",
                "from huggingface_hub import hf_hub_download\n",
                "import cartopy.crs as ccrs\n",
                "import cartopy.feature as cfeature\n",
                "import scipy.signal\n",
                "\n",
                "from granitewxc.utils.config import get_config\n",
                "from granitewxc.utils.data import _get_transforms\n",
                "from granitewxc.datasets.merra2 import Merra2DownscaleDataset\n",
                "from granitewxc.utils.downscaling_model import get_finetune_model\n",
                "from PrithviWxC.dataloaders.merra2 import SampleSpec\n",
                "\n",
                "torch.jit.enable_onednn_fusion(True)\n",
                "if torch.cuda.is_available():\n",
                "    torch.backends.cudnn.benchmark = True\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "\n",
                "# random.seed(42)\n",
                "# if torch.cuda.is_available():\n",
                "#     torch.cuda.manual_seed(42)\n",
                "# torch.manual_seed(42)\n",
                "# np.random.seed(42)\n",
                "\n",
                "device = torch.device(\n",
                "    \"cuda\" if torch.cuda.is_available()\n",
                "    else \"mps\" if torch.backends.mps.is_available()\n",
                "    else \"cpu\"\n",
                ")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "22135603",
            "metadata": {},
            "source": [
                "## 3. Load Model Configuration\n",
                "\n",
                "We use a `config.yaml` file to define the data variables, model parameters, and training settings. This ensures the model is rebuilt exactly as it was during fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34d71033",
            "metadata": {},
            "outputs": [],
            "source": [
                "config_path = hf_hub_download(repo_id=\"ibm-granite/granite-geospatial-wxc-downscaling\",\n",
                "                            filename=\"config.yaml\",\n",
                "                            local_dir=\"../data\")\n",
                "config = get_config(config_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6e436cd3",
            "metadata": {},
            "source": [
                "## 4. Download Data and Weights\n",
                "\n",
                "We will download sample MERRA-2 data for a single day (Jan 1, 2020) and the pre-trained fine-tuned weights for the downscaling model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f4e8ed2",
            "metadata": {},
            "outputs": [],
            "source": [
                "config.download_path = '../data'\n",
                "\n",
                "# Download Model Weights\n",
                "hf_hub_download(repo_id=\"ibm-granite/granite-geospatial-wxc-downscaling\", filename=\"pytorch_model.bin\", local_dir=config.download_path)\n",
                "\n",
                "# Download Sample Data (Surface and Vertical levels)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"merra-2/MERRA2_sfc_20200101.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"merra-2/MERRA_pres_20200101.nc\", local_dir=config.download_path)\n",
                "\n",
                "# Download Climatology / Scalers\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/anomaly_variance_surface.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/anomaly_variance_vertical.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/musigma_surface.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/musigma_vertical.nc\", local_dir=config.download_path)\n",
                "\n",
                "# Download Climatology Mean Files (for normalization)\n",
                "for hour in [0, 3, 6, 9, 12, 15, 18, 21]:\n",
                "    h_str = f\"{hour:02d}\"\n",
                "    hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=f\"climatology/climate_surface_doy001_hour{h_str}.nc\", local_dir=config.download_path)\n",
                "    hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=f\"climatology/climate_vertical_doy001_hour{h_str}.nc\", local_dir=config.download_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5efa4355",
            "metadata": {},
            "source": [
                "## 5. Prepare Dataset and Dataloader\n",
                "\n",
                "The `Merra2DownscaleDataset` handles the data preparation:\n",
                "1.  **Input**: It applies a \"coarsening\" transform to the original MERRA-2 data to simulate a low-resolution input.\n",
                "2.  **Target**: It uses the original high-resolution MERRA-2 data as the ground truth."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59216008",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set paths in config\n",
                "config.data.data_path_surface = os.path.join(config.download_path,'merra-2')\n",
                "config.data.data_path_vertical = os.path.join(config.download_path, 'merra-2')\n",
                "config.data.climatology_path_surface = os.path.join(config.download_path,'climatology')\n",
                "config.data.climatology_path_vertical = os.path.join(config.download_path,'climatology')\n",
                "\n",
                "config.model.input_scalers_surface_path = os.path.join(config.download_path,'climatology/musigma_surface.nc')\n",
                "config.model.input_scalers_vertical_path = os.path.join(config.download_path,'climatology/musigma_vertical.nc')\n",
                "config.model.output_scalers_surface_path = os.path.join(config.download_path,'climatology/anomaly_variance_surface.nc')\n",
                "config.model.output_scalers_vertical_path = os.path.join(config.download_path,'climatology/anomaly_variance_vertical.nc')\n",
                "\n",
                "# Set time range for validation\n",
                "config.data.val_time_range_start = '2020-01-01T00:00:00'\n",
                "config.data.val_time_range_end = '2020-01-01T23:59:59'\n",
                "\n",
                "# Initialize Dataset\n",
                "dataset = Merra2DownscaleDataset(\n",
                "    time_range=(config.data.val_time_range_start, config.data.val_time_range_end),\n",
                "    data_path_surface = config.data.data_path_surface,\n",
                "    data_path_vertical = config.data.data_path_vertical,\n",
                "    climatology_path_surface = config.data.climatology_path_surface,\n",
                "    climatology_path_vertical = config.data.climatology_path_vertical,\n",
                "    input_surface_vars = config.data.input_surface_vars,\n",
                "    input_static_surface_vars = config.data.input_static_surface_vars,\n",
                "    input_vertical_vars = config.data.input_vertical_vars,\n",
                "    input_levels = config.data.input_levels,\n",
                "    n_input_timestamps = config.data.n_input_timestamps,\n",
                "    output_vars=config.data.output_vars,\n",
                "    transforms=_get_transforms(config),\n",
                ")\n",
                "\n",
                "dataloader = DataLoader(dataset, batch_size=1)\n",
                "print(f\"Dataset initialized with {len(dataset)} samples.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1025047",
            "metadata": {},
            "source": [
                "## 6. Initialize Model and Load Weights\n",
                "\n",
                "We initialize the `ClimateDownscaleFinetuneModel`. This specific architecture adds an upscaling head to the core Prithvi WxC encoder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3bd08be8",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = get_finetune_model(config, logger=None)\n",
                "\n",
                "weights_path = Path(config.download_path, 'pytorch_model.bin')\n",
                "model.load_state_dict(torch.load(weights_path, weights_only=False, map_location=device))\n",
                "model.to(device)\n",
                "print(\"Model loaded successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "682dfdca",
            "metadata": {},
            "source": [
                "## 7. Run Inference\n",
                "\n",
                "We'll run the model on a single sample from our dataloader."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0c928e5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    model.eval()\n",
                "\n",
                "    batch = next(iter(dataloader))\n",
                "    batch = {k: v.to(device) for k, v in batch.items()}\n",
                "    out = model(batch)\n",
                "\n",
                "    inputs = batch['x']\n",
                "    targets = batch['y']\n",
                "    outputs = out\n",
                "\n",
                "    inputs = batch['x']\n",
                "    targets = batch['y']\n",
                "    outputs = out\n",
                "\n",
                "print(\"Inference complete.\")\n",
                "print(f\"Input shape: {inputs.shape}\")\n",
                "print(f\"Target shape: {targets.shape}\")\n",
                "print(f\"Output shape: {outputs.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "91642e39",
            "metadata": {},
            "source": [
                "## 8. Visualization\n",
                "\n",
                "We compare the **Input** (Low Res), **Prediction** (Downscaled High Res), and **Ground Truth** (Original High Res)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0de74aae",
            "metadata": {},
            "outputs": [],
            "source": [
                "var_name = \"T2M\"\n",
                "var_name_title = '2M air temperature'\n",
                "\n",
                "input_vars = [*config.data.input_surface_vars, *product(config.data.input_vertical_vars, config.data.input_levels)]\n",
                "input_t2m_index = input_vars.index(var_name)\n",
                "\n",
                "# Extract data for plotting\n",
                "plot_input = inputs[0, input_t2m_index, :, :].detach().cpu().numpy()\n",
                "plot_target = targets[0, 0, : ,:].detach().cpu().numpy()\n",
                "plot_output = outputs[0, 0, :, :].detach().cpu().numpy()\n",
                "plot_residual = plot_target - plot_output\n",
                "\n",
                "fig, axes = plt.subplots(1, 4, figsize=(24, 6), subplot_kw={'projection': ccrs.PlateCarree(central_longitude=180)})\n",
                "\n",
                "# Common features\n",
                "for ax in axes:\n",
                "    ax.coastlines()\n",
                "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
                "    ax.gridlines(draw_labels=False, alpha=0.5, linestyle='--')\n",
                "\n",
                "# Input (Low Res)\n",
                "im0 = axes[0].imshow(plot_input, origin='lower', cmap='plasma', transform=ccrs.PlateCarree())\n",
                "axes[0].set_title(f'Input (Low Res)\\n{plot_input.shape}')\n",
                "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
                "\n",
                "# Prediction (High Res)\n",
                "im1 = axes[1].imshow(plot_output, origin='lower', cmap='plasma', transform=ccrs.PlateCarree())\n",
                "axes[1].set_title(f'Prediction (High Res)\\n{plot_output.shape}')\n",
                "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
                "\n",
                "# Ground Truth (High Res)\n",
                "im2 = axes[2].imshow(plot_target, origin='lower', cmap='plasma', transform=ccrs.PlateCarree())\n",
                "axes[2].set_title(f'Ground Truth (High Res)\\n{plot_target.shape}')\n",
                "plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
                "\n",
                "# Residual / Error\n",
                "im3 = axes[3].imshow(plot_residual, origin='lower', cmap='bwr', vmin=-5, vmax=5, transform=ccrs.PlateCarree())\n",
                "axes[3].set_title(f'Residual (Target - Pred)')\n",
                "plt.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
                "\n",
                "plt.suptitle(f\"Downscaling Results for {var_name_title} (Pacific View)\", fontsize=16)\n",
                "plt.tight_layout()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7a4d57d3",
            "metadata": {},
            "source": [
                "### Power Spectrum Analysis\n",
                "\n",
                "To evaluate how well the model captures fine-scale details, we compute the **Radially Averaged Power Spectrum**. This allows us to compare the energy distribution across different spatial frequencies (wavenumbers). A good downscaling model should recover the high-frequency components (high wavenumbers) that correspond to fine details, matching the ground truth."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2ff5276c",
            "metadata": {},
            "outputs": [],
            "source": [
                "def compute_psd(image):\n",
                "    ny, nx = image.shape\n",
                "    fourier_image = np.fft.fftn(image)\n",
                "    fourier_amplitudes = np.abs(fourier_image)**2\n",
                "    \n",
                "    kfreq_y = np.fft.fftfreq(ny) * ny\n",
                "    kfreq_x = np.fft.fftfreq(nx) * nx\n",
                "    kfreq2D = np.meshgrid(kfreq_x, kfreq_y)\n",
                "    knrm = np.sqrt(kfreq2D[0]**2 + kfreq2D[1]**2)\n",
                "    \n",
                "    knrm = knrm.flatten()\n",
                "    fourier_amplitudes = fourier_amplitudes.flatten()\n",
                "    \n",
                "    kbins = np.arange(0.5, min(ny, nx)//2+1, 1.)\n",
                "    kvals = 0.5 * (kbins[1:] + kbins[:-1])\n",
                "    \n",
                "    Abins, _, _ = scipy.stats.binned_statistic(knrm, fourier_amplitudes, \n",
                "                                                statistic = \"mean\", \n",
                "                                                bins = kbins)\n",
                "    Abins *= np.pi * (kbins[1:]**2 - kbins[:-1]**2)\n",
                "    \n",
                "    return kvals, Abins"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8ac81e52",
            "metadata": {},
            "source": [
                "Now we calculate the PSD for the input, target, and model output."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1b584619",
            "metadata": {},
            "outputs": [],
            "source": [
                "k_input, psd_input = compute_psd(plot_input)\n",
                "k_target, psd_target = compute_psd(plot_target)\n",
                "k_output, psd_output = compute_psd(plot_output)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c0e7d7e5",
            "metadata": {},
            "source": [
                "### Plotting the Power Spectrum\n",
                "\n",
                "  *   **Low Res Input (Green)**: Should drop off at lower wavenumbers, indicating a lack of fine details.\n",
                "  *   **Ground Truth (Black)**: The reference spectrum we want to match.\n",
                "  *   **Prediction (Blue)**: Ideally, this should follow the black line closely, recovering the high frequencies lost in the input."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c1f0a95c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Power Spectrum Plot ---\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "\n",
                "ax.loglog(k_input, psd_input, label='Input (Low Res)', color='green', linestyle='--')\n",
                "ax.loglog(k_target, psd_target, label='Target (Ground Truth)', color='black')\n",
                "ax.loglog(k_output, psd_output, label='Prediction (Prithvi WxC)', color='blue')\n",
                "\n",
                "ax.set_xlabel('Wavenumber (k)')\n",
                "ax.set_ylabel('Power Spectral Density')\n",
                "ax.set_title('Radially Averaged Power Spectrum')\n",
                "ax.legend()\n",
                "ax.grid(True, which=\"both\", ls=\"-\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hidsi_wxclim",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
