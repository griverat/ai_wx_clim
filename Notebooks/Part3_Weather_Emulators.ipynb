{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "b2e1a3a6",
            "metadata": {},
            "source": [
                "# Part 3: Weather Foundational Model with Prithvi WxC\n",
                "\n",
                "## Introduction\n",
                "\n",
                "In this part of the workshop, we will explore the concept of **Weather Foundational Models** and use a state-of-the-art model called **Prithvi WxC** for a downscaling task.\n",
                "\n",
                "### What is a Weather Foundational Model?\n",
                "\n",
                "A **Foundational Model** in the context of weather and climate is a large AI model trained on vast amounts of meteorological data (like ERA5 or MERRA-2 reanalysis data). Unlike traditional numerical weather prediction (NWP) models that solve complex physical equations, these AI models learn the underlying physics and patterns of the atmosphere directly from the data. They are designed to be:\n",
                "\n",
                "*   **General-purpose**: Once pre-trained, they can be fine-tuned for various downstream tasks such as forecasting, downscaling, or gravity wave parameterization.\n",
                "*   **Efficient**: Inference is typically much faster than running high-resolution physical simulations.\n",
                "\n",
                "### Prithvi WxC\n",
                "\n",
                "**Prithvi WxC** is a 2.3 billion parameter Foundational Model developed by IBM and NASA. It is based on a **Vision Transformer (ViT)** architecture with an encoder-decoder structure. It treats weather data as a sequence of tokens, allowing it to capture both local and global interactions in the atmosphere.\n",
                "\n",
                "### The Task: Downscaling\n",
                "\n",
                "**Downscaling** is the process of generating high-resolution weather data from low-resolution inputs. This is crucial for local impact assessments where we need detailed information (e.g., city-level temperature) that global models (with coarse grids like 50km or 100km) cannot provide.\n",
                "\n",
                "In this notebook, we will use a fine-tuned version of Prithvi WxC to downscale **2-meter Temperature (T2M)** from the MERRA-2 dataset, increasing its resolution by **6x**.\n",
                "\n",
                "Let's get started!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation\n",
                "\n",
                "We need to install the `PrithviWxC` and `granitewxc` libraries, along with standard data handling libraries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "053677a4",
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "except:\n",
                "    IN_COLAB = False\n",
                "\n",
                "if IN_COLAB:\n",
                "    print(\"Running on Google Colab. Installing dependencies...\")\n",
                "    !pip install h5netcdf matplotlib wget pyyaml xarray scipy torch PrithviWxC granitewxc huggingface_hub\n",
                "else:\n",
                "    print(\"Running locally. Skipping dependency installation.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0bd3cbc0",
            "metadata": {},
            "source": [
                "## 2. Imports and Configuration\n",
                "\n",
                "Import the necessary modules and set up the computing device (GPU is highly recommended)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6acec501",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import wget\n",
                "import random\n",
                "from pathlib import Path\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "from itertools import product\n",
                "import numpy as np\n",
                "import torch\n",
                "from torch.utils.data import DataLoader\n",
                "from huggingface_hub import hf_hub_download\n",
                "\n",
                "from granitewxc.utils.config import get_config\n",
                "from granitewxc.utils.data import _get_transforms\n",
                "from granitewxc.datasets.merra2 import Merra2DownscaleDataset\n",
                "from granitewxc.utils.downscaling_model import get_finetune_model\n",
                "from PrithviWxC.dataloaders.merra2 import SampleSpec\n",
                "\n",
                "torch.jit.enable_onednn_fusion(True)\n",
                "if torch.cuda.is_available():\n",
                "    torch.backends.cudnn.benchmark = True\n",
                "    torch.backends.cudnn.deterministic = True\n",
                "\n",
                "random.seed(42)\n",
                "if torch.cuda.is_available():\n",
                "    torch.cuda.manual_seed(42)\n",
                "torch.manual_seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "device = torch.device(\n",
                "    \"cuda\" if torch.cuda.is_available()\n",
                "    else \"mps\" if torch.backends.mps.is_available()\n",
                "    else \"cpu\"\n",
                ")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "22135603",
            "metadata": {},
            "source": [
                "## 3. Load Model Configuration\n",
                "\n",
                "We use a `config.yaml` file to define the data variables, model parameters, and training settings. This ensures the model is rebuilt exactly as it was during fine-tuning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "34d71033",
            "metadata": {},
            "outputs": [],
            "source": [
                "config_path = hf_hub_download(repo_id=\"ibm-granite/granite-geospatial-wxc-downscaling\",\n",
                "                            filename=\"config.yaml\",\n",
                "                            local_dir=\"../data\")\n",
                "config = get_config(config_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6e436cd3",
            "metadata": {},
            "source": [
                "## 4. Download Data and Weights\n",
                "\n",
                "We will download sample MERRA-2 data for a single day (Jan 1, 2020) and the pre-trained fine-tuned weights for the downscaling model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0f4e8ed2",
            "metadata": {},
            "outputs": [],
            "source": [
                "config.download_path = '../data'\n",
                "\n",
                "# Download Model Weights\n",
                "hf_hub_download(repo_id=\"ibm-granite/granite-geospatial-wxc-downscaling\", filename=\"pytorch_model.bin\", local_dir=config.download_path)\n",
                "\n",
                "# Download Sample Data (Surface and Vertical levels)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"merra-2/MERRA2_sfc_20200101.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"merra-2/MERRA_pres_20200101.nc\", local_dir=config.download_path)\n",
                "\n",
                "# Download Climatology / Scalers\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/anomaly_variance_surface.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/anomaly_variance_vertical.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/musigma_surface.nc\", local_dir=config.download_path)\n",
                "hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=\"climatology/musigma_vertical.nc\", local_dir=config.download_path)\n",
                "\n",
                "# Download Climatology Mean Files (for normalization)\n",
                "for hour in [0, 3, 6, 9, 12, 15, 18, 21]:\n",
                "    h_str = f\"{hour:02d}\"\n",
                "    hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=f\"climatology/climate_surface_doy001_hour{h_str}.nc\", local_dir=config.download_path)\n",
                "    hf_hub_download(repo_id=\"ibm-nasa-geospatial/Prithvi-WxC-1.0-2300M\", filename=f\"climatology/climate_vertical_doy001_hour{h_str}.nc\", local_dir=config.download_path)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5efa4355",
            "metadata": {},
            "source": [
                "## 5. Prepare Dataset and Dataloader\n",
                "\n",
                "The `Merra2DownscaleDataset` handles the data preparation:\n",
                "1.  **Input**: It applies a \"coarsening\" transform to the original MERRA-2 data to simulate a low-resolution input.\n",
                "2.  **Target**: It uses the original high-resolution MERRA-2 data as the ground truth."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59216008",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set paths in config\n",
                "config.data.data_path_surface = os.path.join(config.download_path,'merra-2')\n",
                "config.data.data_path_vertical = os.path.join(config.download_path, 'merra-2')\n",
                "config.data.climatology_path_surface = os.path.join(config.download_path,'climatology')\n",
                "config.data.climatology_path_vertical = os.path.join(config.download_path,'climatology')\n",
                "\n",
                "config.model.input_scalers_surface_path = os.path.join(config.download_path,'climatology/musigma_surface.nc')\n",
                "config.model.input_scalers_vertical_path = os.path.join(config.download_path,'climatology/musigma_vertical.nc')\n",
                "config.model.output_scalers_surface_path = os.path.join(config.download_path,'climatology/anomaly_variance_surface.nc')\n",
                "config.model.output_scalers_vertical_path = os.path.join(config.download_path,'climatology/anomaly_variance_vertical.nc')\n",
                "\n",
                "# Set time range for validation\n",
                "config.data.val_time_range_start = '2020-01-01T00:00:00'\n",
                "config.data.val_time_range_end = '2020-01-01T23:59:59'\n",
                "\n",
                "# Initialize Dataset\n",
                "dataset = Merra2DownscaleDataset(\n",
                "    time_range=(config.data.val_time_range_start, config.data.val_time_range_end),\n",
                "    data_path_surface = config.data.data_path_surface,\n",
                "    data_path_vertical = config.data.data_path_vertical,\n",
                "    climatology_path_surface = config.data.climatology_path_surface,\n",
                "    climatology_path_vertical = config.data.climatology_path_vertical,\n",
                "    input_surface_vars = config.data.input_surface_vars,\n",
                "    input_static_surface_vars = config.data.input_static_surface_vars,\n",
                "    input_vertical_vars = config.data.input_vertical_vars,\n",
                "    input_levels = config.data.input_levels,\n",
                "    n_input_timestamps = config.data.n_input_timestamps,\n",
                "    output_vars=config.data.output_vars,\n",
                "    transforms=_get_transforms(config),\n",
                ")\n",
                "\n",
                "dataloader = DataLoader(dataset, batch_size=1)\n",
                "print(f\"Dataset initialized with {len(dataset)} samples.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b1025047",
            "metadata": {},
            "source": [
                "## 6. Initialize Model and Load Weights\n",
                "\n",
                "We initialize the `ClimateDownscaleFinetuneModel`. This specific architecture adds an upscaling head to the core Prithvi WxC encoder."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3bd08be8",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = get_finetune_model(config, logger=None)\n",
                "\n",
                "weights_path = Path(config.download_path, 'pytorch_model.bin')\n",
                "model.load_state_dict(torch.load(weights_path, weights_only=False, map_location=device))\n",
                "model.to(device)\n",
                "print(\"Model loaded successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "682dfdca",
            "metadata": {},
            "source": [
                "## 7. Run Inference\n",
                "\n",
                "We'll run the model on a single sample from our dataloader."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0c928e5f",
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    model.eval()\n",
                "\n",
                "    batch = next(iter(dataloader))\n",
                "    batch = {k: v.to(device) for k, v in batch.items()}\n",
                "    out = model(batch)\n",
                "\n",
                "    inputs = batch['x']\n",
                "    targets = batch['y']\n",
                "    outputs = out\n",
                "\n",
                "    inputs = batch['x']\n",
                "    targets = batch['y']\n",
                "    outputs = out\n",
                "\n",
                "print(\"Inference complete.\")\n",
                "print(f\"Input shape: {inputs.shape}\")\n",
                "print(f\"Target shape: {targets.shape}\")\n",
                "print(f\"Output shape: {outputs.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Visualization\n",
                "\n",
                "Let's compare the **input** (low resolution), **prediction** (downscaled high resolution), and **target** (original high resolution) side-by-side."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "var_name = \"T2M\"\n",
                "var_name_title = '2M air temperature'\n",
                "\n",
                "input_vars = [*config.data.input_surface_vars, *product(config.data.input_vertical_vars, config.data.input_levels)]\n",
                "input_t2m_index = input_vars.index(var_name)\n",
                "\n",
                "# Extract data for plotting\n",
                "plot_input = inputs[0, input_t2m_index, :, :].detach().cpu().numpy()\n",
                "plot_target = targets[0, 0, : ,:].detach().cpu().numpy()\n",
                "plot_output = outputs[0, 0, :, :].detach().cpu().numpy()\n",
                "plot_residual = plot_target - plot_output\n",
                "\n",
                "fig, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
                "\n",
                "# Input (Low Res)\n",
                "im0 = axes[0].imshow(plot_input, origin='lower', cmap='plasma')\n",
                "axes[0].set_title(f'Input (Low Res)\\n{plot_input.shape}')\n",
                "plt.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
                "\n",
                "# Prediction (High Res)\n",
                "im1 = axes[1].imshow(plot_output, origin='lower', cmap='plasma')\n",
                "axes[1].set_title(f'Prediction (High Res)\\n{plot_output.shape}')\n",
                "plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
                "\n",
                "# Ground Truth (High Res)\n",
                "im2 = axes[2].imshow(plot_target, origin='lower', cmap='plasma')\n",
                "axes[2].set_title(f'Ground Truth (High Res)\\n{plot_target.shape}')\n",
                "plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
                "\n",
                "# Residual / Error\n",
                "im3 = axes[3].imshow(plot_residual, origin='lower', cmap='bwr', vmin=-5, vmax=5)\n",
                "axes[3].set_title(f'Residual (Target - Pred)')\n",
                "plt.colorbar(im3, ax=axes[3], fraction=0.046, pad=0.04)\n",
                "\n",
                "plt.suptitle(f\"Downscaling Results for {var_name_title}\", fontsize=16)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "hidsi_wxclim",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
